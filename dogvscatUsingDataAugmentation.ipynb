{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9e3e0d-5d3a-4c37-bbc8-2969ed5b86e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\sahub\\appdata\\roaming\\python\\python311\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\sahub\\appdata\\roaming\\python\\python311\\site-packages (from opencv-python) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f33309e-7bfb-4fbc-b2a5-b579d061d913",
   "metadata": {},
   "source": [
    "# Dog Cat Classifier without data augmentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67134609-02f8-4db0-b297-21279759dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8434a921-3d09-416f-b730-a17f8bff5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir=r\"dog_catsDataset\\train\"\n",
    "\n",
    "categories=['cats','dogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fecc339-7f52-4ad2-9f9f-f831d3800c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in categories:\n",
    "    folder_path=os.path.join(mydir,i)\n",
    "    if i=='cats':\n",
    "        label=0\n",
    "    else:\n",
    "        label=1\n",
    "    for j in os.listdir(folder_path):\n",
    "        img_path=os.path.join(folder_path,j)\n",
    "        img=cv2.imread(img_path)\n",
    "        img=cv2.resize(img,(150,150))\n",
    "        data.append([img,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce10a351-52a8-4caa-91de-76335d2d456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac90b8c-ac26-41f9-9e1d-0f6739c436da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for i in data:\n",
    "    X.append(i[0])\n",
    "    y.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daa4099c-c6fe-4711-a852-a523002f3304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1725, 150, 150, 3), (1725,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "X=np.array(X)\n",
    "\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b927fcf-d223-4d68-bca4-65e2087df04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725, 150, 150, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71458ea9-6bb9-4cbe-93cb-ed2f61cfb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten , Activation, Dropout, Input,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "032e6c59-7487-4185-ae67-f730c980aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=(150,150,3)))\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be09ebbd-a773-4acd-91f5-80f55930190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 275ms/step - accuracy: 0.4847 - loss: 0.6935 - val_accuracy: 0.5665 - val_loss: 0.6916\n",
      "Epoch 2/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - accuracy: 0.5213 - loss: 0.6928 - val_accuracy: 0.5665 - val_loss: 0.6906\n",
      "Epoch 3/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 215ms/step - accuracy: 0.5289 - loss: 0.6922 - val_accuracy: 0.5665 - val_loss: 0.6902\n",
      "Epoch 4/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - accuracy: 0.4960 - loss: 0.6937 - val_accuracy: 0.5665 - val_loss: 0.6894\n",
      "Epoch 5/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - accuracy: 0.5308 - loss: 0.6918 - val_accuracy: 0.5665 - val_loss: 0.6896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2cd592bc310>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=5,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb6748b-ad08-4e06-bbb6-6f0ed31513e0",
   "metadata": {},
   "source": [
    "# Using Data Augmentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20bdb40f-3f27-419b-84b8-37745eb99ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1725 images belonging to 2 classes.\n",
      "Found 403 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# creating more images for training\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size=16\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "#generator\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    r\"dog_catsDataset\\train\",\n",
    "    target_size=(150,150),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "    r\"dog_catsDataset\\valid\",\n",
    "    target_size=(150,150),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2afca-a2d3-4326-81c4-0f5a832bfb5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ffb93d1-8cb3-4db9-9a05-1cb067e95acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=(150,150,3)))\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d621fcff-02ec-460d-b646-361bd791d68b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 275ms/step - accuracy: 0.5624 - loss: 0.6787 - val_accuracy: 0.5275 - val_loss: 0.6899\n",
      "Epoch 2/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.5000 - loss: 0.6786 - val_accuracy: 0.3333 - val_loss: 0.7261\n",
      "Epoch 3/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 299ms/step - accuracy: 0.5660 - loss: 0.6797 - val_accuracy: 0.5625 - val_loss: 0.6752\n",
      "Epoch 4/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.5000 - loss: 0.7034 - val_accuracy: 0.3333 - val_loss: 0.7076\n",
      "Epoch 5/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 286ms/step - accuracy: 0.5897 - loss: 0.6656 - val_accuracy: 0.5600 - val_loss: 0.6688\n",
      "Epoch 6/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.5625 - loss: 0.6487 - val_accuracy: 0.0000e+00 - val_loss: 0.8698\n",
      "Epoch 7/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 286ms/step - accuracy: 0.6136 - loss: 0.6517 - val_accuracy: 0.6325 - val_loss: 0.6521\n",
      "Epoch 8/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.7500 - loss: 0.5727 - val_accuracy: 1.0000 - val_loss: 0.5320\n",
      "Epoch 9/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 285ms/step - accuracy: 0.6497 - loss: 0.6439 - val_accuracy: 0.6275 - val_loss: 0.6438\n",
      "Epoch 10/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.6875 - loss: 0.6114 - val_accuracy: 0.3333 - val_loss: 0.6837\n",
      "Epoch 11/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 279ms/step - accuracy: 0.6574 - loss: 0.6143 - val_accuracy: 0.5925 - val_loss: 0.6833\n",
      "Epoch 12/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.6875 - loss: 0.6252 - val_accuracy: 0.6667 - val_loss: 0.7160\n",
      "Epoch 13/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 276ms/step - accuracy: 0.6517 - loss: 0.6232 - val_accuracy: 0.6525 - val_loss: 0.6359\n",
      "Epoch 14/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7500 - loss: 0.5838 - val_accuracy: 0.6667 - val_loss: 0.5894\n",
      "Epoch 15/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 269ms/step - accuracy: 0.6797 - loss: 0.5983 - val_accuracy: 0.6675 - val_loss: 0.6392\n",
      "Epoch 16/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8750 - loss: 0.5001 - val_accuracy: 0.6667 - val_loss: 0.5609\n",
      "Epoch 17/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 276ms/step - accuracy: 0.7089 - loss: 0.5717 - val_accuracy: 0.6750 - val_loss: 0.6132\n",
      "Epoch 18/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.7500 - loss: 0.6057 - val_accuracy: 0.6667 - val_loss: 0.6821\n",
      "Epoch 19/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 276ms/step - accuracy: 0.7029 - loss: 0.5860 - val_accuracy: 0.6700 - val_loss: 0.6314\n",
      "Epoch 20/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.6875 - loss: 0.5868 - val_accuracy: 0.3333 - val_loss: 0.7327\n",
      "Epoch 21/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.7186 - loss: 0.5597 - val_accuracy: 0.6875 - val_loss: 0.5978\n",
      "Epoch 22/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.8125 - loss: 0.5425 - val_accuracy: 0.6667 - val_loss: 0.5908\n",
      "Epoch 23/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 267ms/step - accuracy: 0.6872 - loss: 0.5766 - val_accuracy: 0.6575 - val_loss: 0.6304\n",
      "Epoch 24/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.5000 - loss: 0.6042 - val_accuracy: 1.0000 - val_loss: 0.5157\n",
      "Epoch 25/25\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 276ms/step - accuracy: 0.7608 - loss: 0.5258 - val_accuracy: 0.6875 - val_loss: 0.6220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2cd58025cd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=1725//batch_size,epochs=25,validation_data=test_generator, validation_steps=403//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6244b4-1f23-4ece-94fe-81d98ba65850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "721aafc9-ef4d-481f-98ba-0f4335b417c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import urllib.request\n",
    "\n",
    "# Step 1: Load the image from a URL using OpenCV\n",
    "url = \"https://www.argospetinsurance.co.uk/assets/uploads/2017/12/cat-pet-animal-domestic-104827.jpeg\"\n",
    "resp = urllib.request.urlopen(url)\n",
    "image_array = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "img = cv2.resize(img, (150, 150))\n",
    "\n",
    "img=img/255.0\n",
    "\n",
    "img = img.reshape(1,150,150,3)\n",
    "\n",
    "\n",
    "prediction = model.predict(img)\n",
    "prediction = 1 if prediction >= 0.5 else 0\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba1d7583-bca1-4566-9236-f86584fbc0e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msahub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPrtc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcat.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m))\n\u001b[0;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\sahub\\OneDrive\\Desktop\\Desktop\\Prtc\\train\\cat.jpg\")\n",
    "img = cv2.resize(img, (150, 150))\n",
    "img = img / 255.0\n",
    "img = img.reshape(1,150,150,3)\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "prediction = 1 if prediction >= 0.5 else 0\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fe87486-cc68-4baa-8caa-5192008cc6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(r\"C:\\Users\\sahub\\OneDrive\\Desktop\\Desktop\\Prtc\\train\\dog.jpg\")\n",
    "img = cv2.resize(img, (150, 150))\n",
    "img = img / 255.0\n",
    "img = img.reshape(1,150,150,3)\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "prediction = 1 if prediction >= 0.5 else 0\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3be76f-7c26-4943-bc47-1aff74e22d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf693e11-dfef-49b2-bbc3-6671e4087965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d9e61-fe63-4b4b-aabd-54337805d307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68799f-0081-4a73-9d6b-ad58cb4548d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2be5fc-023c-4145-81fa-e4399c471ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e9aa8-10eb-415b-9ee8-e5de5bc37eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c972fb-1cf8-4d46-9b21-3621ee5bfef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1c734-27a5-4bc8-8f4a-bf19d4f9e190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9faa77-43c1-4041-8366-edeb97432165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c24155-f5ab-408d-92ec-4573c0a0e0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08516894-0b5d-44e6-a6ec-d31e635db7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb0dd6-02dd-4f44-acbe-8c20dd0f6aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f48070-b502-4c07-a699-88b3b1ad959c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2bde06-0ae5-42d4-990d-a49d5532d9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17212c29-07e6-429b-8c7d-57c93fce1584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042785f6-654e-4780-9461-24318450df03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30f063-19e8-4131-8f4c-c98e5f0f1725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4a6f3-e0b8-411e-8c0b-b34be8b7a9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
